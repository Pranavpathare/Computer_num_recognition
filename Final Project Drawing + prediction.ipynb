{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 95s 2ms/step - loss: 0.2601 - acc: 0.9200 - val_loss: 0.0550 - val_acc: 0.9829\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 95s 2ms/step - loss: 0.0874 - acc: 0.9731 - val_loss: 0.0369 - val_acc: 0.9866\n",
      "Epoch 3/4\n",
      " 4992/60000 [=>............................] - ETA: 1:21 - loss: 0.0663 - acc: 0.9814"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 4\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0703 20:50:23.427294 26148 deprecation_wrapper.py:119] From C:\\Users\\prana\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0703 20:50:23.445722 26148 deprecation_wrapper.py:119] From C:\\Users\\prana\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0703 20:50:23.493658 26148 deprecation_wrapper.py:119] From C:\\Users\\prana\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0703 20:50:23.496255 26148 deprecation_wrapper.py:119] From C:\\Users\\prana\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0703 20:50:23.496255 26148 deprecation_wrapper.py:119] From C:\\Users\\prana\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0703 20:50:23.508196 26148 deprecation.py:506] From C:\\Users\\prana\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0703 20:50:23.634210 26148 deprecation_wrapper.py:119] From C:\\Users\\prana\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0703 20:50:23.709798 26148 deprecation_wrapper.py:119] From C:\\Users\\prana\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0703 20:50:23.872650 26148 deprecation.py:323] From C:\\Users\\prana\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('my_model_mnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pred(img):\n",
    "    global model\n",
    "    return np.argmax(model.predict(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(img):\n",
    "    back = np.zeros((500,500,3))\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(back,str(model_pred(img)),(100,400), font, 15,(255,255,255),10,cv2.LINE_AA)\n",
    "    plt.imshow(back,cmap = 'gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_processing(store):\n",
    "    img = store[-1]\n",
    "    img = img[20:260,:]\n",
    "    #img = 255 - img\n",
    "    img = cv2.GaussianBlur(img,(5,5),0)\n",
    "    img = cv2.erode(img,(3,3),iterations = 3)\n",
    "    img = cv2.dilate(img,(3,3),iterations = 10)\n",
    "    #plt.imshow(img,cmap =  'gray')\n",
    "    img = cv2.resize(img,(28,28))\n",
    "    #plt.imshow(img,cmap = 'gray')\n",
    "    img = np.reshape(img,(1,28,28,1))\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = None\n",
    "accumulated_weight = 0.5\n",
    "\n",
    "roi_top = 20\n",
    "roi_bottom = 400\n",
    "roi_right = 300\n",
    "roi_left = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accum_avg(frame,accumulated_weight):\n",
    "    \n",
    "    global background\n",
    "    \n",
    "    if background is None:\n",
    "        background = frame.copy().astype(\"float\")\n",
    "        return None\n",
    "    cv2.accumulateWeighted(frame,background,accumulated_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(frame,threshold=25):\n",
    "    \n",
    "    global background\n",
    "    \n",
    "    diff = cv2.absdiff(background.astype(\"uint8\"),frame)\n",
    "    _,thresholded = cv2.threshold(diff,threshold,255,cv2.THRESH_BINARY)\n",
    "    contours,hierarchy =  cv2.findContours(thresholded.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        hand_segment = max(contours,key = cv2.contourArea)\n",
    "        return (thresholded,hand_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(a,b):\n",
    "    return math.sqrt((a[0] - b[0])**2 + (b[1] - a[1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_points(points,filterValue):\n",
    "    for i in range(len(points)):\n",
    "        for j in range(i+1,len(points)):\n",
    "            if points[i] and points[j] and dist(points[i] , points[j]) < filterValue:\n",
    "                points[j] = None\n",
    "    filtered = []\n",
    "    for point in points:\n",
    "        if point is not None:\n",
    "            filtered.append(point)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame,points):\n",
    "    for point in points:\n",
    "        cv2.circle(frame,point,radius = 5,color = (0,0,255),thickness = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_screen():\n",
    "    return np.zeros((380,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "#cam.set(cv2.CAP_PROP_FPS,90)\n",
    "num_frames = 0\n",
    "screen = np.zeros((380,300))\n",
    "\n",
    "store = []\n",
    "\n",
    "curr = None\n",
    "prev = None\n",
    "\n",
    "# keep looping, until interrupted\n",
    "while True:\n",
    "\n",
    "    ret, frame = cam.read()\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    frame_copy = frame.copy()\n",
    "\n",
    "    roi = frame[roi_top:roi_bottom, roi_right:roi_left]\n",
    "    #print(roi.shape)\n",
    "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "\n",
    "    if num_frames < 60:\n",
    "        calc_accum_avg(gray, accumulated_weight)\n",
    "        if num_frames <= 59:\n",
    "            cv2.putText(frame_copy, \"WAIT! GETTING BACKGROUND AVG.\", (20, 400), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,255,0), 2)\n",
    "            cv2.imshow(\"Finger Count\",frame_copy)\n",
    "            \n",
    "    else:\n",
    "\n",
    "        hand = segment(gray)\n",
    "\n",
    "        if hand is not None:\n",
    "            thresholded, hand_segment = hand\n",
    "            masked = cv2.bitwise_and(roi,roi,mask = thresholded)\n",
    "            #cv2.imshow(\"Masked\",masked)\n",
    "            #cv2.imshow(\"Thesholded\", thresholded)\n",
    "            contours,hierarchy = cv2.findContours(thresholded,\n",
    "                                                  cv2.RETR_TREE,\n",
    "                                                  cv2.CHAIN_APPROX_SIMPLE)\n",
    "            palm_area = 0\n",
    "            flag = None\n",
    "            cnt = None\n",
    "            \n",
    "            for (i,c) in enumerate(contours):\n",
    "                area = cv2.contourArea(c)\n",
    "                if area>palm_area:\n",
    "                    palm_area = area\n",
    "                    flag = i\n",
    "            if flag is not None and palm_area > 10000:\n",
    "                cnt = contours[flag]\n",
    "                cv2.drawContours(masked,[cnt],0,(0,255,0),2)\n",
    "                cv2.imshow(\"roi_contours\",masked)\n",
    "                points = []\n",
    "                hull = cv2.convexHull(cnt,returnPoints = False)\n",
    "                defects = cv2.convexityDefects(cnt,hull)\n",
    "                \n",
    "                for i in range(defects.shape[0]):\n",
    "                    s,e,f,d, = defects[i,0]\n",
    "                    end = tuple(cnt[e][0])\n",
    "                    points.append(end)\n",
    "    \n",
    "                filtered = filter_points(points,50)#.sort(key = lambda x:x[1])\n",
    "                filtered.sort(key = lambda point : point[1])\n",
    "                fingers = [pt for (idx,pt) in zip(range(1),filtered)]\n",
    "                plot(masked,fingers)\n",
    "    \n",
    "                cv2.imshow(\"roi_contours\",masked)\n",
    "               \n",
    "                prev = curr\n",
    "                curr = fingers[0]\n",
    "                \n",
    "                if prev and curr:\n",
    "                    cv2.line(screen,prev,curr,(255,255,255),3)\n",
    "                cv2.imshow(\"Drawing\",screen)\n",
    "                \n",
    "                \n",
    "                k = cv2.waitKey(10)\n",
    "                if k == ord('a'):\n",
    "                    store.append(screen)\n",
    "                    screen = get_new_screen()\n",
    "                      \n",
    "    cv2.rectangle(frame_copy, (roi_left, roi_top), (roi_right, roi_bottom), (0,0,255), 5)\n",
    "\n",
    "    num_frames += 1\n",
    "    cv2.imshow(\"Finger Count\", frame_copy)\n",
    "\n",
    "    k = cv2.waitKey(12) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image_processing(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0703 20:59:35.154932 26148 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
